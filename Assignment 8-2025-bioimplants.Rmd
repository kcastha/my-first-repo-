---
title: "Assignment 8-Bioimplants"
author: "Astha K C"
date: "4/11/2025"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## read libraries and Load data

```{r}
library(tidyverse)
library(caret)
bi <- read_csv("bioimplants.csv")
bi$attrition <- as.factor(bi$attrition)
bi<-  bi %>% mutate(genderMale = ifelse(gender=="Male",1,0),
                    over_timeYes = ifelse(over_time=="Yes",1,0))

```


## Description of Data
- *age*:   age of employee in years.	
- *gender*: Male/Female                     
- *monthly_income*: salary per month in $.          
- *num_companies_worked*: number of companies at which the employee has previously worked.
- *over_time*:  indicator variable for whether the employee has worked more than 40 hours per week.   
- *years_at_company*:  number of years the employee has worked at the company.
- *attrition*: indicator for whether the employee left the company in 2016.


The goal of this assignment is to be able to compare and choose among various classification models, specifically, among logistic regression models. We will review the various measures: AIC, Accuracy, and AUC.


### Question 1 (2 points)
Rank the following four logistic regression models based on their AIC performance. Compute AIC for each and then pick the best model.
- attrition ~ age+ monthly_income
- attrition ~ age+ monthly_income + years_at_company
- attrition ~ age+ monthly_income + years_at_company + genderMale 
- attrition ~ age+ monthly_income + years_at_company + genderMale + num_companies_worked +over_timeYes

> Answer: 

```{r}
glm(attrition ~ age + monthly_income, data = bi, family = "binomial") %>% summary()
glm(attrition ~ age + monthly_income + years_at_company, data = bi,family = binomial) %>% summary()
glm(attrition ~ age + monthly_income + years_at_company + genderMale, data = bi,family = binomial) %>% summary()
glm(attrition ~ age + monthly_income + years_at_company + genderMale + num_companies_worked +over_timeYes, data = bi,family = binomial) %>% summary()

```
Model 4 is the best model based on AIC, as it has the lowest AIC value which is 848.97.
Rank:
1. attrition ~ age+ monthly_income + years_at_company + genderMale + num_companies_worked +over_timeYes 
2. attrition ~ age + monthly_income + years_at_company 
3. attrition ~ age + monthly_income + years_at_company + genderMale 
4. attrition ~ age + monthly_income

### Question 2 (2 points)
For the above four models compare the train (in-sample) vs. test (out-of-sample) Accuracy. Which model is the best based on train Accuracy and test Accuracy? Use 5-fold cross validation for all computations of test Accuracy.

> Answer: 

```{r}
set.seed(123)
caret_glm1 <- train(attrition ~ age + monthly_income,
                   data = bi,
                   method = "glm",
                   trControl = trainControl(method = "cv",  
                                                 number = 5,
                                                 verboseIter = T)) 
set.seed(123)
caret_glm2 <- train(attrition ~ age + monthly_income + years_at_company,
                   data = bi,
                   method = "glm",
                   trControl = trainControl(method = "cv", 
                                                 number = 5,
                                                 verboseIter = T)) 
set.seed(123)
caret_glm3 <- train(attrition ~ age + monthly_income + years_at_company + genderMale,
                   data = bi,
                   method = "glm",
                   trControl = trainControl(method = "cv",  
                                                 number = 5,
                                                 verboseIter = T)) 

set.seed(123)
caret_glm4 <- train(attrition ~ age + monthly_income + years_at_company + genderMale + num_companies_worked + over_timeYes,
                   data = bi,
                   method = "glm",
                   trControl = trainControl(method = "cv",  # bootstrapping
                                                 number = 5,
                                                 verboseIter = T)) 

# for in-sample accuracy
mean(predict(caret_glm1,data = bi,type = "raw")==bi$attrition)
mean(predict(caret_glm2,data = bi,type = "raw")==bi$attrition)
mean(predict(caret_glm3,data = bi,type = "raw")==bi$attrition)
mean(predict(caret_glm4,data = bi,type = "raw")==bi$attrition)

# out-of-sample accuracy
caret_glm1$results$Accuracy
caret_glm2$results$Accuracy
caret_glm3$results$Accuracy
caret_glm4$results$Accuracy

```
Model 4 has the highest train accuracy which is 85.88% and test accuracy which is 85.52%.This means that model4 is performing better in-sample and out-of-sample,without overfitting.Therefore, model4 is the best model for predicting employee attrition because overtime is a variabe that has a high Pr(>|z|)
considering outcome o the reut is similar wheere s probability doesnot give same resut 

## Question 3 (2 points)
Consider the logistic regression

 - attrition ~ age + monthly_income + genderMale + num_companies_worked + over_time+years_at_company

and the *majority class* rule. What is the (train) accuracy obtained using the *majority class* rule?

> Answer: 

```{r}
# what is in-sample accuracy with majority class rule?
table(bi$attrition) %>% prop.table()
```
The train accuracy using the majority class rule is 83.5%, which is "No", and if we always predicted "No", we would be right 83.5% of the time having no attrition.
majority class rule : no matter the data the result is no .

## Question 4 (2 points)
Consider the logistic regression

 - attrition ~ age + monthly_income + genderMale + num_companies_worked + over_time + years_at_company
 
and class decision thresholds of 0.6 and 0.75. What are the train accuracy measures obtained using these decision thresholds? Which decision threshold gives the best accuracy for the above logistic regression model?

> Answer: 

```{r}
# accuracy with 0.6 and 0.75
predict4 <- predict(caret_glm4,data = bi,type = "prob") # predict in-sample probabilities using 'caret_glm4' model
predict4 <- predict4 %>% mutate(Class_60 = ifelse(predict4$Yes>=0.6,"Yes","No"), # for 60% class threshold
                                Class_75 = ifelse(predict4$Yes>=0.75,"Yes","No") # for 75% class threshold
                                )

#in-sample accuracy 
mean(predict4$Class_60==bi$attrition) # with 60% class threshold
mean(predict4$Class_75==bi$attrition) # with 75% class threshold

```
 Train accuracy at 60% threshold is 84.52% and train accuracy at 75% threshold is 83.42%.The 60% threshold gives higher accuracy than 75%.Therefore, the decision threshold of 60% gives the best accuracy for this logistic regression model.
  
## Question 5 (2 points)
Consider the logistic regression

 - attrition ~ age + monthly_income + genderMale + num_companies_worked + over_time + years_at_company
 
For the above model, use the *confusionMatrix* function to compute the below measures for a *decision threshold of 0.6*. Assume that *Attrition = Yes* represents the *positive* class.

- True positive rate
- True negative rate
- False positive rate
- False negative rate

> Answer: 

```{r}
predict4 <- predict4 %>% mutate(Class_60= as.factor(Class_60),
                                Class_75= as.factor(Class_75))

confusionMatrix(predict4$Class_60, reference = bi$attrition, positive = "Yes")



```
True Positive Rate is 7.7% which identifies only 7.7% of employees who actually left.
True Negative Rate is 99.8% which perfectly predicts employees who stayed.
False Positive Rate is 0.2% which is very few false alarms.
False Negative Rate 92.3% which is a very large portion of employees who left were not detected. 

true negative is 914+2 : 914/ 916 
true positive is 14+168 we want high 14 divide by 182: sensitivity 
false positive : 2/ 914+2 or 1-true poaitive 

 
 The model with a threshold of 0.6 is very conservtive it predicts someone will leave unless the probability is quite high. 
 
 
 This is the statistics assignment that i did in first semester. 


